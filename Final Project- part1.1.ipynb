{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a8be8-6430-4ae5-ac26-f0534f906d4a",
   "metadata": {},
   "source": [
    "### 1. Downloading Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "391fde12-5f5e-47fe-ae34-0a9e3dc6b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Yellow Taxi files...\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet. Skipping.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet. Skipping.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-09.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-12.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-10.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-11.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-11.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-12.parquet. Skipping.\n",
      "Downloading FHVHV files...\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-02.parquet. Skipping.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-04.parquet. Skipping.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-06.parquet. Skipping.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet  after 3 attempts.\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet : HTTP 403\n",
      "Failed to download https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet  after 3 attempts.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-09.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-10.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-11.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-12.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-09.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-10.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-11.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-12.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-01.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-03.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-04.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-05.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-06.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-07.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-08.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-09.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-10.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-11.parquet. Skipping.\n",
      "Invalid content type for https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-12.parquet. Skipping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_parquet_links(url, regex_pattern):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = [link.get('href') for link in soup.find_all('a', href=True)]\n",
    "    return [link for link in links if re.search(regex_pattern, link)]\n",
    "\n",
    "def download_parquet_files(links, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for link in links:\n",
    "        file_name = os.path.join(save_dir, os.path.basename(link))\n",
    "        response = requests.get(link, stream=True)\n",
    "        with open(file_name, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "# Filter links in date range\n",
    "def filter_links_by_date(links, start_date, end_date):\n",
    "\n",
    "    filtered_links = []\n",
    "    for link in links:\n",
    "        match = re.search(r'(\\d{4})-(\\d{2})', link)\n",
    "        if match:\n",
    "            year, month = int(match.group(1)), int(match.group(2))\n",
    "            date = datetime(year, month, 1)\n",
    "            if start_date <= date <= end_date:\n",
    "                filtered_links.append(link)\n",
    "    return filtered_links\n",
    "\n",
    "# Define date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2024, 8, 1)\n",
    "\n",
    "url = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "yellow_regex = r'yellow_tripdata_\\d{4}-\\d{2}\\.parquet'\n",
    "fhvhv_regex = r'fhvhv_tripdata_\\d{4}-\\d{2}\\.parquet'\n",
    "\n",
    "# Fetch links\n",
    "yellow_links = get_parquet_links(url, yellow_regex)\n",
    "fhvhv_links = get_parquet_links(url, fhvhv_regex)\n",
    "\n",
    "# Filter links by date\n",
    "yellow_links_filtered = filter_links_by_date(yellow_links, start_date, end_date)\n",
    "fhvhv_links_filtered = filter_links_by_date(fhvhv_links, start_date, end_date)\n",
    "\n",
    "# Download filtered files\n",
    "download_parquet_files(yellow_links_filtered, \"yellow_taxi_data\")\n",
    "download_parquet_files(fhvhv_links_filtered, \"fhvhv_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7914d1-4540-4db7-9692-94107d86a256",
   "metadata": {},
   "source": [
    "### 2. Sampling with Cochran's Formula\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d984bbc2-7713-4e3c-928e-d7c4da66506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a52e6-4a02-49e4-b17c-0c5ea71af16b",
   "metadata": {},
   "source": [
    "#### 2.1 Define the Sampling Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dfb0fb3-a5df-4f4c-a6ad-625692adde70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cochran_sample_size(population_size, confidence_level=0.95, p=0.5, margin_of_error=0.05):\n",
    "    # Z-scores for common confidence levels\n",
    "    z_scores = {0.9: 1.645, 0.95: 1.96, 0.99: 2.576}\n",
    "    z = z_scores[confidence_level]\n",
    "    \n",
    "    # Cochran's initial sample size\n",
    "    n_0 = (z**2 * p * (1 - p)) / (margin_of_error**2)\n",
    "    \n",
    "    # Adjust sample size for finite population\n",
    "    if population_size > 0:\n",
    "        n = n_0 / (1 + (n_0 - 1) / population_size)\n",
    "    else:\n",
    "        n = n_0  # Default to initial sample size if population size is unknown\n",
    "    \n",
    "    return math.ceil(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858550f-25c0-41e1-acb3-c38ab23dc2e4",
   "metadata": {},
   "source": [
    "#### 2.2 Sampling for Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b37e8db1-3649-4746-8050-715554bd1ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi - yellow_tripdata_2020-01.parquet: Population size = 6405008, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-01.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-02.parquet: Population size = 6299367, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-02.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-03.parquet: Population size = 3007687, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-03.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-04.parquet: Population size = 238073, Sample size = 384\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-04.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-05.parquet: Population size = 348415, Sample size = 384\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-05.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-06.parquet: Population size = 549797, Sample size = 384\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-06.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-07.parquet: Population size = 800412, Sample size = 384\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-07.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-08.parquet: Population size = 1007286, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-08.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-09.parquet: Population size = 1341017, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-09.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-10.parquet: Population size = 1681132, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-10.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-11.parquet: Population size = 1509000, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-11.parquet\n",
      "Yellow Taxi - yellow_tripdata_2020-12.parquet: Population size = 1461898, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2020-12.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-01.parquet: Population size = 1369769, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-01.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-02.parquet: Population size = 1371709, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-02.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-03.parquet: Population size = 1925152, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-03.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-04.parquet: Population size = 2171187, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-04.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-05.parquet: Population size = 2507109, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-05.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-06.parquet: Population size = 2834264, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-06.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-07.parquet: Population size = 2821746, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-07.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-08.parquet: Population size = 2788757, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-08.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-09.parquet: Population size = 2963793, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-09.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-10.parquet: Population size = 3463504, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-10.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-11.parquet: Population size = 3472949, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-11.parquet\n",
      "Yellow Taxi - yellow_tripdata_2021-12.parquet: Population size = 3214369, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2021-12.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-01.parquet: Population size = 2463931, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-01.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-02.parquet: Population size = 2979431, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-02.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-03.parquet: Population size = 3627882, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-03.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-04.parquet: Population size = 3599920, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-04.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-05.parquet: Population size = 3588295, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-05.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-06.parquet: Population size = 3558124, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-06.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-07.parquet: Population size = 3174394, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-07.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-08.parquet: Population size = 3152677, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-08.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-09.parquet: Population size = 3183767, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-09.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-10.parquet: Population size = 3675411, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-10.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-11.parquet: Population size = 3252717, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-11.parquet\n",
      "Yellow Taxi - yellow_tripdata_2022-12.parquet: Population size = 3399549, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2022-12.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-01.parquet: Population size = 3066766, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-01.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-02.parquet: Population size = 2913955, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-02.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-03.parquet: Population size = 3403766, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-03.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-04.parquet: Population size = 3288250, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-04.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-05.parquet: Population size = 3513649, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-05.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-06.parquet: Population size = 3307234, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-06.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-07.parquet: Population size = 2907108, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-07.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-08.parquet: Population size = 2824209, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-08.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-09.parquet: Population size = 2846722, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-09.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-10.parquet: Population size = 3522285, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-10.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-11.parquet: Population size = 3339715, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-11.parquet\n",
      "Yellow Taxi - yellow_tripdata_2023-12.parquet: Population size = 3376567, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2023-12.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-01.parquet: Population size = 2964624, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-01.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-02.parquet: Population size = 3007526, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-02.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-03.parquet: Population size = 3582628, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-03.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-04.parquet: Population size = 3514289, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-04.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-05.parquet: Population size = 3723833, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-05.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-06.parquet: Population size = 3539193, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-06.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-07.parquet: Population size = 3076903, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-07.parquet\n",
      "Yellow Taxi - yellow_tripdata_2024-08.parquet: Population size = 2979183, Sample size = 385\n",
      "Sampled data saved to: yellow_taxi_sampled_data/yellow_tripdata_2024-08.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-01.parquet: Population size = 20569368, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-01.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-02.parquet: Population size = 21725100, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-02.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-03.parquet: Population size = 13392928, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-03.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-04.parquet: Population size = 4312909, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-04.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-05.parquet: Population size = 6089999, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-05.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-06.parquet: Population size = 7555193, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-06.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-07.parquet: Population size = 9958454, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-07.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-08.parquet: Population size = 11096852, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-08.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-09.parquet: Population size = 12106669, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-09.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-10.parquet: Population size = 13268411, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-10.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-11.parquet: Population size = 11596865, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-11.parquet\n",
      "FHVHV - fhvhv_tripdata_2020-12.parquet: Population size = 11637123, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2020-12.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-01.parquet: Population size = 11908468, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-01.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-02.parquet: Population size = 11613942, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-02.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-03.parquet: Population size = 14227393, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-03.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-04.parquet: Population size = 14111371, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-04.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-05.parquet: Population size = 14719171, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-05.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-06.parquet: Population size = 14961892, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-06.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-07.parquet: Population size = 15027174, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-07.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-08.parquet: Population size = 14499696, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-08.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-09.parquet: Population size = 14886055, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-09.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-10.parquet: Population size = 16545356, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-10.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-11.parquet: Population size = 16041639, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-11.parquet\n",
      "FHVHV - fhvhv_tripdata_2021-12.parquet: Population size = 16054495, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2021-12.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-01.parquet: Population size = 14751591, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-01.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-02.parquet: Population size = 16019283, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-02.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-03.parquet: Population size = 18453548, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-03.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-04.parquet: Population size = 17752561, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-04.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-05.parquet: Population size = 18157335, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-05.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-06.parquet: Population size = 17780075, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-06.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-07.parquet: Population size = 17464619, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-07.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-08.parquet: Population size = 17185687, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-08.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-09.parquet: Population size = 17793551, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-09.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-10.parquet: Population size = 19306090, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-10.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-11.parquet: Population size = 18085896, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-11.parquet\n",
      "FHVHV - fhvhv_tripdata_2022-12.parquet: Population size = 19665847, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2022-12.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-01.parquet: Population size = 18479031, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-01.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-02.parquet: Population size = 17960971, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-02.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-04.parquet: Population size = 19144903, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-04.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-05.parquet: Population size = 19847676, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-05.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-06.parquet: Population size = 19366619, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-06.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-07.parquet: Population size = 19132131, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-07.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-08.parquet: Population size = 18322150, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-08.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-09.parquet: Population size = 19851123, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-09.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-10.parquet: Population size = 20186330, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-10.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-11.parquet: Population size = 19269250, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-11.parquet\n",
      "FHVHV - fhvhv_tripdata_2023-12.parquet: Population size = 20516297, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2023-12.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-01.parquet: Population size = 19663930, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-01.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-02.parquet: Population size = 19359148, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-02.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-03.parquet: Population size = 21280788, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-03.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-04.parquet: Population size = 19733038, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-04.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-05.parquet: Population size = 20704538, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-05.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-06.parquet: Population size = 20123226, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-06.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-07.parquet: Population size = 19182934, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-07.parquet\n",
      "FHVHV - fhvhv_tripdata_2024-08.parquet: Population size = 19128392, Sample size = 385\n",
      "Sampled data saved to: fhvhv_sampled_data/fhvhv_tripdata_2024-08.parquet\n"
     ]
    }
   ],
   "source": [
    "# Function to sample a monthly dataset\n",
    "def sample_monthly_data(file_path, sample_size):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    sampled_df = df.sample(n=sample_size, random_state=42) \n",
    "    return sampled_df\n",
    "\n",
    "# Sampling logic for Yellow Taxi and FHVHV datasets\n",
    "def process_data(data_path_pattern, output_dir, dataset_type):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "    file_paths = sorted(glob.glob(data_path_pattern))  # Get all matching files\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        # Load dataset to calculate population size\n",
    "        population_size = len(pd.read_parquet(file_path))\n",
    "        \n",
    "        # Calculate sample size\n",
    "        sample_size = cochran_sample_size(population_size, confidence_level=0.95, margin_of_error=0.05)\n",
    "        print(f\"{dataset_type} - {os.path.basename(file_path)}: Population size = {population_size}, Sample size = {sample_size}\")\n",
    "        \n",
    "        # Sample data\n",
    "        sampled_data = sample_monthly_data(file_path, sample_size)\n",
    "        \n",
    "        # Save sampled data\n",
    "        output_file = os.path.join(output_dir, os.path.basename(file_path))\n",
    "        sampled_data.to_parquet(output_file)\n",
    "        print(f\"Sampled data saved to: {output_file}\")\n",
    "\n",
    "\n",
    "# Process both datasets\n",
    "process_data(\"yellow_taxi_data/yellow_tripdata_202*.parquet\", \"yellow_taxi_sampled_data\", \"Yellow Taxi\")\n",
    "process_data(\"fhvhv_data/fhvhv_tripdata_202*.parquet\", \"fhvhv_sampled_data\", \"FHVHV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93e4fb40-e9b4-4ad1-b3bd-c42d47798291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9141359</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-16 12:51:16</td>\n",
       "      <td>2022-06-16 12:52:50</td>\n",
       "      <td>2022-06-16 12:52:58</td>\n",
       "      <td>2022-06-16 13:05:22</td>\n",
       "      <td>242</td>\n",
       "      <td>185</td>\n",
       "      <td>2.330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.27</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125422</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-11 09:01:19</td>\n",
       "      <td>2022-06-11 09:08:04</td>\n",
       "      <td>2022-06-11 09:08:23</td>\n",
       "      <td>2022-06-11 09:34:46</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>5.380</td>\n",
       "      <td>...</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.38</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227438</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B03406</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-06-19 16:30:56</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-06-19 16:40:00</td>\n",
       "      <td>2022-06-19 16:58:08</td>\n",
       "      <td>234</td>\n",
       "      <td>142</td>\n",
       "      <td>2.742</td>\n",
       "      <td>...</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.84</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10779540</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-18 22:34:47</td>\n",
       "      <td>2022-06-18 22:41:40</td>\n",
       "      <td>2022-06-18 22:42:11</td>\n",
       "      <td>2022-06-18 22:47:50</td>\n",
       "      <td>197</td>\n",
       "      <td>134</td>\n",
       "      <td>1.280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767195</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-17 12:17:01</td>\n",
       "      <td>2022-06-17 12:21:21</td>\n",
       "      <td>2022-06-17 12:23:12</td>\n",
       "      <td>2022-06-17 12:45:46</td>\n",
       "      <td>61</td>\n",
       "      <td>39</td>\n",
       "      <td>3.720</td>\n",
       "      <td>...</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.84</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373264</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-03 11:04:14</td>\n",
       "      <td>2022-06-03 11:04:37</td>\n",
       "      <td>2022-06-03 11:06:36</td>\n",
       "      <td>2022-06-03 11:08:59</td>\n",
       "      <td>79</td>\n",
       "      <td>113</td>\n",
       "      <td>0.280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.37</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689953</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-10 16:54:35</td>\n",
       "      <td>2022-06-10 17:06:35</td>\n",
       "      <td>2022-06-10 17:06:50</td>\n",
       "      <td>2022-06-10 17:50:58</td>\n",
       "      <td>69</td>\n",
       "      <td>182</td>\n",
       "      <td>5.310</td>\n",
       "      <td>...</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.02</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906917</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-12 12:03:36</td>\n",
       "      <td>2022-06-12 12:11:27</td>\n",
       "      <td>2022-06-12 12:13:28</td>\n",
       "      <td>2022-06-12 13:38:38</td>\n",
       "      <td>246</td>\n",
       "      <td>129</td>\n",
       "      <td>27.500</td>\n",
       "      <td>...</td>\n",
       "      <td>8.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>78.30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156960</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B03406</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-06-16 12:39:43</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-06-16 12:41:30</td>\n",
       "      <td>2022-06-16 13:11:25</td>\n",
       "      <td>244</td>\n",
       "      <td>163</td>\n",
       "      <td>7.110</td>\n",
       "      <td>...</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.39</td>\n",
       "      <td>24.19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16010597</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-06-27 16:06:38</td>\n",
       "      <td>2022-06-27 16:09:57</td>\n",
       "      <td>2022-06-27 16:09:57</td>\n",
       "      <td>2022-06-27 18:00:16</td>\n",
       "      <td>230</td>\n",
       "      <td>132</td>\n",
       "      <td>24.340</td>\n",
       "      <td>...</td>\n",
       "      <td>11.21</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.63</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "9141359             HV0003               B03404               B03404   \n",
       "6125422             HV0003               B03404               B03404   \n",
       "11227438            HV0005               B03406                 None   \n",
       "10779540            HV0003               B03404               B03404   \n",
       "9767195             HV0003               B03404               B03404   \n",
       "...                    ...                  ...                  ...   \n",
       "1373264             HV0003               B03404               B03404   \n",
       "5689953             HV0003               B03404               B03404   \n",
       "6906917             HV0003               B03404               B03404   \n",
       "9156960             HV0005               B03406                 None   \n",
       "16010597            HV0003               B03404               B03404   \n",
       "\n",
       "            request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "9141359  2022-06-16 12:51:16 2022-06-16 12:52:50 2022-06-16 12:52:58   \n",
       "6125422  2022-06-11 09:01:19 2022-06-11 09:08:04 2022-06-11 09:08:23   \n",
       "11227438 2022-06-19 16:30:56                 NaT 2022-06-19 16:40:00   \n",
       "10779540 2022-06-18 22:34:47 2022-06-18 22:41:40 2022-06-18 22:42:11   \n",
       "9767195  2022-06-17 12:17:01 2022-06-17 12:21:21 2022-06-17 12:23:12   \n",
       "...                      ...                 ...                 ...   \n",
       "1373264  2022-06-03 11:04:14 2022-06-03 11:04:37 2022-06-03 11:06:36   \n",
       "5689953  2022-06-10 16:54:35 2022-06-10 17:06:35 2022-06-10 17:06:50   \n",
       "6906917  2022-06-12 12:03:36 2022-06-12 12:11:27 2022-06-12 12:13:28   \n",
       "9156960  2022-06-16 12:39:43                 NaT 2022-06-16 12:41:30   \n",
       "16010597 2022-06-27 16:06:38 2022-06-27 16:09:57 2022-06-27 16:09:57   \n",
       "\n",
       "            dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  \\\n",
       "9141359  2022-06-16 13:05:22           242           185       2.330  ...   \n",
       "6125422  2022-06-11 09:34:46            17            39       5.380  ...   \n",
       "11227438 2022-06-19 16:58:08           234           142       2.742  ...   \n",
       "10779540 2022-06-18 22:47:50           197           134       1.280  ...   \n",
       "9767195  2022-06-17 12:45:46            61            39       3.720  ...   \n",
       "...                      ...           ...           ...         ...  ...   \n",
       "1373264  2022-06-03 11:08:59            79           113       0.280  ...   \n",
       "5689953  2022-06-10 17:50:58            69           182       5.310  ...   \n",
       "6906917  2022-06-12 13:38:38           246           129      27.500  ...   \n",
       "9156960  2022-06-16 13:11:25           244           163       7.110  ...   \n",
       "16010597 2022-06-27 18:00:16           230           132      24.340  ...   \n",
       "\n",
       "          sales_tax  congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "9141359        1.01                  0.00          0.0  0.00        9.27   \n",
       "6125422        2.59                  0.00          0.0  0.00       26.38   \n",
       "11227438       2.13                  2.75          0.0  0.00       14.84   \n",
       "10779540       0.70                  0.00          0.0  0.00        6.94   \n",
       "9767195        2.45                  0.00          0.0  0.00       21.84   \n",
       "...             ...                   ...          ...   ...         ...   \n",
       "1373264        0.68                  2.75          0.0  0.00        8.37   \n",
       "5689953        3.06                  0.00          0.0  0.00       31.02   \n",
       "6906917        8.35                  2.75          0.0  0.00       78.30   \n",
       "9156960        2.63                  2.75          0.0  5.39       24.19   \n",
       "16010597      11.21                  2.75          2.5  0.00       86.63   \n",
       "\n",
       "          shared_request_flag  shared_match_flag  access_a_ride_flag  \\\n",
       "9141359                     N                  N                       \n",
       "6125422                     N                  N                       \n",
       "11227438                    N                  N                   N   \n",
       "10779540                    N                  N                       \n",
       "9767195                     N                  N                       \n",
       "...                       ...                ...                 ...   \n",
       "1373264                     N                  N                       \n",
       "5689953                     N                  N                       \n",
       "6906917                     N                  N                       \n",
       "9156960                     N                  N                   N   \n",
       "16010597                    N                  N                       \n",
       "\n",
       "          wav_request_flag wav_match_flag  \n",
       "9141359                  N              N  \n",
       "6125422                  N              N  \n",
       "11227438                 N              N  \n",
       "10779540                 N              N  \n",
       "9767195                  N              N  \n",
       "...                    ...            ...  \n",
       "1373264                  N              N  \n",
       "5689953                  N              N  \n",
       "6906917                  N              N  \n",
       "9156960                  N              N  \n",
       "16010597                 N              N  \n",
       "\n",
       "[385 rows x 24 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the file\n",
    "file_path = \"/Users/vivianwang/Desktop/GitHub/final_project01/fhvhv_sampled_data/fhvhv_tripdata_2022-06.parquet\"\n",
    "\n",
    "# Read the file\n",
    "df1 = pd.read_parquet(file_path)\n",
    "\n",
    "# Display column names\n",
    "df1\n",
    "\n",
    "# Path to the file\n",
    "file_path = \"/Users/vivianwang/Desktop/GitHub/final_project01/fhvhv_sampled_data/fhvhv_tripdata_2022-06.parquet\"\n",
    "\n",
    "# Read the file\n",
    "df1 = pd.read_parquet(file_path)\n",
    "\n",
    "# Display column names\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_tlc_page(taxi_page):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_parquet_urls(all_urls):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_month(url):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month(parquet_url)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.contact(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    all_urls = get_all_urls_from_taxi_page(TLC_URL)\n",
    "    all_parquet_urls = find_taxi_parquet_urls(all_urls)\n",
    "    taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07574983-f41d-4cd6-8f70-489493089b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(url):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d85ff-313c-41a2-9a46-261a9a2bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(parquet_urls):\n",
    "    all_uber_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_uber_month(parquet_url)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_uber_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    uber_data = pd.contact(all_uber_dataframes)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    all_urls = get_all_urls_from_tlc_page(TLC_URL)\n",
    "    all_parquet_urls = find_parquet_urls(all_urls)\n",
    "    taxi_data = get_and_clean_uber_data(all_parquet_urls)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48216557",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090eb94-a5b0-4d93-bf82-a596d2521b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c074aa3-a5f2-4586-8748-411e1e6c11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23adde",
   "metadata": {},
   "source": [
    "### 3. Cleaning & Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "def clean_and_filter_data(df, zones_shapefile, bounding_box):\n",
    "    zones = gpd.read_file(zones_shapefile)\n",
    "    zones['centroid'] = zones['geometry'].centroid\n",
    "    zone_centroids = zones.set_index('LocationID')['centroid']\n",
    "    df['pickup_location'] = df['PULocationID'].map(zone_centroids)\n",
    "    df['dropoff_location'] = df['DOLocationID'].map(zone_centroids)\n",
    "    df = df.dropna(subset=['pickup_location', 'dropoff_location'])\n",
    "    min_lat, min_lon, max_lat, max_lon = bounding_box\n",
    "    df = df[\n",
    "        (df['pickup_location'].y >= min_lat) &\n",
    "        (df['pickup_location'].y <= max_lat) &\n",
    "        (df['pickup_location'].x >= min_lon) &\n",
    "        (df['pickup_location'].x <= max_lon)\n",
    "    ]\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "bounding_box = (40.560445, -74.242330, 40.908524, -73.717047)\n",
    "zones_shapefile = \"taxi_zones/taxi_zones.shp\"\n",
    "cleaned_data = clean_and_filter_data(sampled_data, zones_shapefile, bounding_box)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
